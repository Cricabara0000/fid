---
title: "Análisis de datos hepáticos"
author: "Julia García Flores, Cristian Antonio Cabello Arango, Paula Yuan César Aguilar, Pablo Santos Alises, Juan María Sojo López"
date: "08-01-2024"
output: html_document
---
# Hepatitis

La hepatitis es una inflamación del hígado que puede ser causada por diversos factores, como infecciones virales, consumo de alcohol, drogas, toxinas, o incluso como resultado de trastornos autoinmunes. En función de la gravedad se clasifican en distintos tipos: A, B, C, D, E, G aunque las mas comunes son la A, B y C. De acuerdo con datos de la Organización Mundial de la Salud (OMS), alrededor de 1,2 millones de personas murieron a causa de hepatitis aguda o alguna de sus secuelas (cáncer o cirrosis) en 2019.


## Lectura del conjunto de datos
```{r}
# Instalar y cargar las librerías necesarias si no están instaladas

# install.packages("dplyr")
# install.packages("ggplot2")
# install.packages("caret")
# install.packages("e1071")
# install.packages("randomForest")
# install.packages("ROCR")
# install.packages("neuralnet")
# install.packages("pROC")


library(dplyr)
library(ggplot2)
library(caret)
library(e1071)
library(randomForest)
library(ROCR)
library(neuralnet)
library(pROC)
```

```{r}
hepatitis<-read.csv("data/hepatitis_csv.csv", header = TRUE,sep=",") 
head(hepatitis)
```

## Análisis de los datos

Lo primero que realizaremos será fijar una semilla para controlar la aletoriedad, si existiera, de algún algoritmo.

```{r}
set.seed(1)
```

A continuación, se muestra un breve descripción de cada uno de los atributos del conjunto de datos, así como una clasificación de dichas variables en función de su tipo (categóricas o numéricas):

```{r}
#Resumen estadístico de los datos
summary(hepatitis)
```

```{r}
str(hepatitis)
```

El conjunto de datos está compuesto por una vista minable de 20 atributos (variables) y 155 ejemplos (observaciones) cada atributo.

Como podemos observar, los atributos o variables presentes en nuestro conjunto de datos, en función de su tipo (categóricas o numéricas), son las siguientes:

1.  **age**: Variable numérica continua que representa la edad de los pacientes. La edad puede ser un factor en la severidad o susceptibilidad a ciertos tipos de hepatitis, por ejemplo, la hepatitis A tiende a ser menos severa en adultos pero más grave en niños.

2.  **sex**: Variable categórica que indica el sexo de los pacientes. Según algunos estudios, en la respuesta inmune entre hombres y mujeres frente a la hepatitis es diferente, aunque estos efectos pueden variar dependiendo del tipo de hepatitis.

3.  **steroid**: Variable categórica que indica si los pacientes recibieron esteroides o no como parte del tratamiento. El uso de esteroides puede influir en la efectividad del tratamiento de la enfermedad hepática.

4.  **antivirals**: Variable categórica que indica si los pacientes recibieron tratamiento antiviral. El uso de medicamentos antivirales puede influir en la progresión de la enfermedad hepática.

5.  **fatigue, malaise, anorexia, liver_big, liver_firm, spleen_palpable, spiders, ascites, varices, histology, class**: Todos estos atributos son variables categóricas que describen diferentes hallazgos físicos obtenidos de las pruebas realizadas sobre los pacientes. Estos hallazgos clínicos pueden indicar complicaciones asociadas con la hepatitis, como cirrosis, hipertensión portal o daño hepático avanzado. Además, proporcionan información detallada sobre el estado del tejido hepático, lo que puede ayudar a determinar la gravedad y la causa subyacente de la hepatitis.

6.  **bilirubin, alk_phosphate, sgot, albumin, protime**: Todos estos atributos son variables numéricas continuas que representan diferentes resultados de pruebas médicas relacionados con la condición de los pacientes. Es decir, son indicativos del funcionamiento hepático y pueden ser utilizados para diagnosticar y monitorizar la hepatitis, ya que los niveles anormales pueden señalar la presencia y severidad de la enfermedad.

Observando el dataset, nos damos cuenta de que todas las variables numéricas son continuas y que todas las variables categóricas, excepto la variable sex, son atributos de tipo Boolean, por ello, decidimos realizar una transformación de variables categóricas utilizando la siguiente técnica:

### Codificación ordinal

Para poder obtener un análisis más completo de este tipo de datos, decidimos realizar una transformación de variables de categóricas a numéricas discretas, es decir, las variables cuyo resultado sea True pasarán a ser el número 1 y, las variables cuyo resultado sea False, pasarán a ser el número 0. Estos atributos nos permitirán obtener una serie de gráficas más concretas que permitan mostrar la distribución de dichos atributos con otros.



```{r}
#ponemos el sexo de male = 0 y female = 1, los True =1 y False = 0 y live = 1 y die = 0
hepatitis<-hepatitis%>%
mutate(steroid=ifelse(steroid=="True",1,0),antivirals=ifelse(antivirals=="True",1,0),fatigue=ifelse(fatigue=="True",1,0),malaise=ifelse(malaise=="True",1,0),anorexia=ifelse(anorexia=="True",1,0),liver_big=ifelse(liver_big=="True",1,0),liver_firm=ifelse(liver_firm=="True",1,0),spleen_palpable=ifelse(spleen_palpable=="True",1,0),spiders=ifelse(spiders=="True",1,0),ascites=ifelse(ascites=="True",1,0),varices=ifelse(varices=="True",1,0),histology=ifelse(histology=="True",1,0))
head(hepatitis)
```


```{r}
str(hepatitis)

```


Las variables que han sido transformadas de categóricas a numéricas discretas, a través de la codificación ordinal, son: 'steroid', 'antivirals', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_fig', 'spleen_palpable', 'spiders', 'ascites', 'varices' e 'histology'.

Una vez tenemos el dataset transformado de forma más sencilla, decidimos proceder a realizar un análisis y limpieza de datos faltantes para poder obtener el conjunto de datos más completo posible y poder graficar los datos de una forma más representativa.

### Análisis de datos faltantes

A continuación, realizaremos una representación de la suma de valores faltantes en cada uno de los atributos presentes en el conjunto de datos:

```{r}
#Función que calcula el número de valores faltantes de cada variable del conjunto de datos hepatitis.
valores_faltantes <- sapply(hepatitis, function(x) sum(is.na(x)))
#Dataframe con el número de valores faltantes por variable del conjunto de datos.
print(valores_faltantes)
#Valores faltantes del todo el conjunto de datos
print(sum(valores_faltantes))
```

Como podemos observar, la mayoría de atributos no continen datos faltantes en sus ejemplos, o tienen muy pocos, de hecho, el conjunto de datos contiene un total de 167 valores faltantes. Sin embargo, se observa que hay un atributo que contiene una gran cantidad de valores faltantes, el atributo "protime", con 67 valores faltantes. Seguido de este atributo, aparecen otros que también contienen un número de valores faltantes significativos que añaden "ruido" y desinformación al conjunto, estos atributos son "alk_phosphate" y "albumin" con 29 y 16 datos faltantes, respectivamente. En concreto:

-   Los atributos'steroid', 'fatigue', 'anorexia', 'liver_big', 'liver_firm', 'spleen_palpable', 'spiders', 'ascites', 'varices', 'bilirubin', 'alk_phosphate', 'sgot', 'albumin', 'protime' tienen 1 o más valores faltantes.

-   Los atributos 'age', 'sex', 'antivirals', 'histology', 'class' no tienen valores faltantes.

Por ello, realizaremos un estudio para poder rellenar los datos en cada uno de los atributos que presentan datos faltantes.

Según las técnicas de preprocesado de valores faltantes, tenemos varias opciones para aplicar en estos casos: eliminar las filas que contengan datos faltantes o rellenar los valores faltantes con propiedades estadísticas de cada uno de los atributos (media, mediana, moda, etc).

```{r}
# Calcular el porcentaje de valores nulos por atributo
porcentaje_valores_nulos <- colSums(is.na(hepatitis)) / nrow(hepatitis) * 100

# Mostrar el porcentaje de valores nulos por atributo
print(porcentaje_valores_nulos)

```

Como podemos observar, el atributo 'protime' presenta un 43'2% de ejemplos nulos en su composición. Según la literatura, comúnmente, se considera eliminar atributos que tienen un alto porcentaje de valores faltantes, superando el umbral del 50%. Sin embargo, esto puede variar según el impacto del atributo en el análisis. En este caso, este atributo no representa una importancia significativa en el problema abordado pues, en su definición, el atributo representa una prueba médica sobre el funcionamiento hepático y en el conjunto de datos hay varias pruebas médicas más que representan lo mismo.

```{r}
mean_protime <- mean(hepatitis$protime, na.rm = TRUE)
print(mean_protime)
```



El atributo 'protime' representa el tiempo de protrombina. La protrombina es una proteína producida por el hígado y es fundamental en el proceso de coagulación sanguínea. La prueba del tiempo de protrombina es un examen de sangre que mide el tiempo que tarda la porción líquida de la sangre (plasma) en coagularse. Niveles anormales pueden ser indicativos de enfermedad hepática. El tiempo de protrombina suele estar alrededor de 11 a 13.5 segundos.

Sin embargo, el código anterior representa que el tiempo de protombina medio de 62 segundos, lo que corresponden a valores anormales en todos los ejemplos e indica que todas las pruebas de tiempo de protombina realizadas sobre los pacientes que forman el conjunto de datos no son significativas pues presentan valores anormales en su conjunto, por lo que, a priori, podemos afirmar que este atributo no presenta un impacto significativo en el conjunto de datos y, por ello, puede ser eliminado sin afectar a la información, el análisis e incluso las predicciones del problema.

```{r}
# Eliminar el atributo 'protime' del conjunto de datos 'hepatitis'
hepatitis <- subset(hepatitis, select = -protime)

# Mostrar la estructura del nuevo conjunto de datos sin 'protime'
str(hepatitis)

```

Como se puede observar, ya se ha eliminado el atributo 'protime' por lo que el conjunto de datos pasa a estar compuesto por 19 variables.

Para el resto de variables, realizaremos un estudio estadístico de los valores de cada atributo en función de su tipo, de la siguiente manera:

1.  Para los atributos que han sido transformados de variables categóricas a valores discretos (de Boolean: True/False a Integer: 1/0) se realizará un estudio de todos sus ejemplos para rellenar los valores faltantes con el valor que más se presente en dicho atributo.

    ```{r}
    variables = c('steroid', 'antivirals', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_firm',
                  'spleen_palpable', 'spiders', 'ascites', 'varices', 'histology')

    # Cáalculo del recuento de valores faltantes para las variables discretas
    for (variable in variables) {
      cat(paste("Variable:", variable, "- Valores faltantes:", sum(is.na(hepatitis[[variable]])), "\n"))
    }

    ```

A continuación, se realizará un recuento de cuántos ejemplos contienen un número uno (son True) y cuántos ejemplos contienen un cero (son False) para rellenar los ejemplos faltantes con el valor que más se repita en cada atributo. Recordamos que las variables que han sido transformadas de categóricas a numéricas discretas son: 'steroid', 'antivirals', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_fig', 'spleen_palpable', 'spiders', 'ascites', 'varices' e 'histology'.


```{r}
for (variable in variables) {
  cat("Variable:", variable, "\n")
  cat("Recuento de 0s:", sum(hepatitis[[variable]] == 0 & !is.na(hepatitis[[variable]])), "\n")
  cat("Recuento de 1s:", sum(hepatitis[[variable]] == 1 & !is.na(hepatitis[[variable]])), "\n\n")
}
```

Como podemos observar, la mayoría de atributos están representados en casi su totalidad por unos o por ceros, por ejemplo, el atributo 'spleen_palpable' está representado en su mayoría por unos, por lo que los valores faltantes de dicho atributo podría ser sustituidos por un uno. Sin embargo, el atributo 'steroid' está representado casi por la misma cantidad de ceros que de unos por lo que puede ser significativo modificar los valores nulos con el número que más se repita. Analizando resultados anteriores, se observa que, únicamente, hay un solo valor nulo en este atributo, por lo que se decide continuar con la decisión de rellenar los valores nulos de los atributos numéricos con el valor que más se repita.

```{r}
# Lista de variables para imputar valores faltantes
variables <- c('steroid', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_firm',
               'spleen_palpable', 'spiders', 'ascites', 'varices')

# Bucle para cada variable
for (variable in variables) {
  # Contar el número de unos y ceros en la columna 'variable'
  count_uno <- sum(hepatitis[[variable]] == 1, na.rm = TRUE)
  count_cero <- sum(hepatitis[[variable]] == 0, na.rm = TRUE)
  
  # Determinar el valor más alto (mayor)
if (count_uno > count_cero) {
    cat(paste("El valor más alto para", variable, "es 1 (unos)\n"))
    hepatitis[[variable]][is.na(hepatitis[[variable]])] <- 1
  } else {
    cat(paste("El valor más alto para", variable, "es 0 (ceros)\n"))
    hepatitis[[variable]][is.na(hepatitis[[variable]])] <- 0
  }
}

sapply(hepatitis[variables], function(x) sum(is.na(x)))
head(hepatitis[variables])
```

Como se puede observar, todos los valores faltantes de las variables numéricas discretas han sido reemplazados correctamente por el número que más se repite entre todos los ejemplos de cada atributo (variable).

2.  Para los valores numéricos continuos, se realizará un estudio estadístico de la media y la mediana que nos permita decidir cuál de estos estadísticos es el más apropiados para reemplazar los valores nulos de dichos atributos. Los atributos numéricos continuos de nuestro conjunto de datos son los siguientes: 'age', 'bilirubin', 'alk_phosphate', 'sgot' y 'albumin'. A continuación, realizaremos el estudio estadístico de la media y la mediana de los atributos 'bilirubin', 'alk_phosphate', 'sgot' y 'albumin' para decidir con qué valores reemplazamos los valores faltantes.

```{r}
# Lista de variables continuas
variables_continuas <- c('bilirubin', 'alk_phosphate', 'sgot', 'albumin')

# Bucle para calcular la media y la mediana de los valores que no son faltantes
for (variable_c in variables_continuas) {
  mean_value <- mean(hepatitis[[variable_c]], na.rm = TRUE)
  median_value <- median(hepatitis[[variable_c]], na.rm = TRUE)
  
  cat(paste("Variable:", variable_c, "\n"))
  cat(paste("Valores faltantes:", sum(is.na(hepatitis[[variable_c]])), "\n"))
  cat(paste("Media:", mean_value, "\n"))
  cat(paste("Mediana:", median_value, "\n\n"))
}

```

Por una parte, el atributo 'age' no contiene valores faltantes en ninguno de sus ejemplos, por lo que no es necesario realizar este análisis para dicho atributo.

Por otra parte, los atributos 'bilirubin' y 'albumin' no presentan mucha diferencia entre la media y la mediana, por lo que se podría elegir cualquier estadístico para reemplazar los valores faltantes de estos atributos. En nuestro caso, observando el conjunto de datos, decidimos utilizar la media (redondeada con dos decimales pues así están los valores en el conjunto de datos) para reemplazar los valores faltantes de estos dos atributos pues presenta un resultado continuo más preciso.

Sin embargo, los atributos 'alk_phosphate' y 'sgot' sí presentan mucha diferencia entre la media y la mediana, por lo que habría que recurrir al conjunto de datos y a la definición de cada atributo para poder decidir qué estadístico utilizar para reemplazar los valores faltantes.

El atributo 'alk_phosphate' representa el nivel de fosfatasa alcalina en el suero del paciente. Los valores elevados de fosfatasa alcalina suelen ser común en enfermedades hepáticas. El rango de valores normales para un adulto suele oscilar entre 20 y 140 unidades/litro. En este caso, tanto la media como la mediana están dentro del rango de valores normales de nivel de fosfatasa alcalina en suero, por lo que elegir un estadístico u otro no debería representar ninguna diferencia significativa a la hora de reemplazar los valores faltantes con alguno de estos valores. Por ello, decidimos reemplazar los valores faltantes de este atributo con la mediana pues es el valor que se representa el valor de la variable en su posición central.

El atributo 'sgot' representa el nivel de enzimas hepáticas (aspartato aminotransferasas) en el suero del paciente. Los valores normales suelen estar en el rango de 10 a 40 unidades/litro en personas adultas. En este caso, ambos valores están fuera del rango de valores normales, por lo que, la elección del estadístico podría representar un resultado significativo a la hora de reemplazar los valores faltantes de este atributo. Sin embargo, dicho atributo, únicamente presenta cuatro valores faltantes en su conjunto. Por ello, se decide utilizar la mediana como estadístico para reemplazar los valores faltantes de este atributo pues, además, se acerca más al rango de valores normales que la media.

Como podemos observar, para la variable 'sex' no ha sido necesario realizar un análisis de valores faltantes pues carece de ellos. En otras palabras, el atributo contiene valores en todos sus ejemplos.

A continuación, realizaremos el reemplazo de los valores faltantes de estos atributos numéricos continuos:

```{r}
# Calcular la media de 'bilirubin' y 'albumin' redondeada a dos decimales
mean_bilirubin <- round(mean(hepatitis$bilirubin, na.rm = TRUE), 2)
mean_albumin <- round(mean(hepatitis$albumin, na.rm = TRUE), 2)

# Reemplazar valores faltantes en 'bilirubin' y 'albumin' con la media redondeada
hepatitis$bilirubin[is.na(hepatitis$bilirubin)] <- mean_bilirubin
hepatitis$albumin[is.na(hepatitis$albumin)] <- mean_albumin

# Calcular la mediana de 'alk_phosphate' y 'sgot'
median_alk_phosphate <- median(hepatitis$alk_phosphate, na.rm = TRUE)
median_sgot <- median(hepatitis$sgot, na.rm = TRUE)

# Reemplazar valores faltantes en 'alk_phosphate' y 'sgot' con la mediana
hepatitis$alk_phosphate[is.na(hepatitis$alk_phosphate)] <- median_alk_phosphate
hepatitis$sgot[is.na(hepatitis$sgot)] <- median_sgot

```

El conjunto de datos tras esta parte del procesamiento queda resultante de la siguiente manera:

```{r}
head(hepatitis)
```

### Visualización

A continuación se muestra una serie de gráficas que permitan representar un análisis exploratorio sobre la distribución de cada una de estas varibles así como la distribución entre varios atributos.

```{r}
variables_discretas <- c('steroid', 'antivirals', 'fatigue', 'malaise', 'anorexia', 'liver_big', 'liver_firm',
               'spleen_palpable', 'spiders', 'ascites', 'varices', 'histology')

# Crear gráficos de barras para cada variable discreta
for (variable_fd in variables_discretas) {
  # Contar la frecuencia de cada valor en la columna
  freq_table <- table(hepatitis[[variable_fd]])
  
  # Convertir la tabla de frecuencias a un dataframe
  freq_df <- as.data.frame(freq_table)
  names(freq_df) <- c(variable_fd, "Frequency")
  
  # Graficar el gráfico de barras
 p <- ggplot(freq_df, aes(x = !!as.name(variable_fd), y = Frequency, fill = !!as.name(variable_fd))) +
    geom_bar(stat = "identity") +
    labs(title = paste("Distribución de", variable_fd)) +
    xlab(variable_fd) +
    ylab("Frecuencia") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = 1))
 print(p)
}

```

Como se puede observar, los gráficos representan la distribución de los valores numéricos discretos.

Por un lado, las gráficas de las variables 'steroid', 'fatigue', 'malaise', 'liver_firm', 'spiders', 'ascites', e 'histology' parecen que están balanceadas pues presentan valores similares de unos y de ceros, por ejemplo, la variable 'steroid' presenta casi el mismo número de unos que de ceros, siendo la variable mejor distribuida y, por lo tanto, la que mejor balanceo presenta.

Por otro lado, las gráficas de las variables 'antivirals', 'anorexia', 'liver_big', 'spleen_palpable' y 'varices' parecen que están desbalanceadas pues presentan más valores de una categoría que de otra, por ejemplo, las variables 'antivirals' y 'varices' presentan más ceros que de unos, siendo las variables que presentan el peor balanceo de todas las variables numéricas discretas.

```{r}
# Lista de variables continuas
variables_continuas <- c('age', 'bilirubin', 'alk_phosphate', 'sgot', 'albumin')

# Crear gráficos de densidad con líneas para cada variable continua
for (variable_fc in variables_continuas) {
  # Crear el gráfico de densidad
  p <- ggplot(hepatitis, aes_string(x = variable_fc)) +
    geom_density(color = "blue") +
    labs(title = paste("Distribución de", variable_fc, "con densidad")) +
    xlab(variable_fc) +
    ylab("Densidad") +
    theme_minimal()
  print(p)
}

```

Realizando un análisis de la distribución de estas gráficas que representan las variables numéricas continuas, podemos observar que las escalas son diferentes entre ellas, de hecho, la variable 'histology' encuentra sus valores dentro del rango [2-6,5] aproximadamente, la variable 'sgot' encuentra sus valores dentro del rango [0-650], la variable 'alk_phosphate' encuentra sus valores dentro del rango [0-300], la variable 'bilirubin' encuentra sus valores dentro del rango [0-8] y la variable 'age' encuentra sus valores dentro del rango [0-80], aproximadamente.

Además, podemos observar que las variables 'age' y 'albumin' representan una gráfica similar a la distribución estadística normalizada en la que la mayoría de datos se distribuyen en el centro. El resto de variables están más distribuidas a la izquierda de la gráfica.

```{r}
ggplot(hepatitis, aes(x = class)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribución de la variable 'class'",
       x = "Clase",
       y = "Frecuencia") +
  theme_minimal()
```

Como podemos observar, la variable dependiente 'class' está desbalanceada, esto significa que la distribución de los ejemplos dentro de esa variable no es uniforme, es decir, hay una gran diferencia en el número de observaciones entre las categorías 'die' y 'live'. Estas categorías infican si el paciente vive o muere por la hepatitis. En este caso, la categoría 'live' contiene más de tres veces más de ejemplos que la categoría 'die'.

El desbalance en los datos puede afectar el rendimiento de los modelos de aprendizaje automático, especialmente en algoritmos que son sensibles a la distribución de clases, ya que pueden tener dificultades para aprender patrones de las clases minoritarias.

Por ello, optamos por realizar una selección de atributos para balancear la variable dependiente y predictora 'class' y seleccionar los atributos que presenten resultados más significativos para realizar un estudio de entrenamientos de modelos.

## Selección de atributos

Para realizar la selección de atributos, todas las variables deben ser numéricas. El problema consiste en que la variable 'sex' y la variable 'class' son variables categóricas. Las categorías de la variable 'sex' son female y male, indicando el sexo del paciente y las categorías de la variable 'class' son die y live, indicando si el paciente muere o vive a la enfermedad de hepatitis. Como se observa, las variables tienen, únicamente, dos categorías, por lo que se podrían transformar a valores binarios, ceros y unos, pero las variables numéricas discretas fueron transformadas de categóricas booleanas a binarias.

Sin embargo, según la literatura, el hecho de que el resto de las variables tengan valores binarios (0 y 1) no es necesariamente un problema en sí mismo ya que el conjuntos de datos puede tener varias variables binarias que representan diferentes características o condiciones sin representar problemas significativos.

Por ello, vamos a realizar la transformación a variables binarias estas variables categóricas discretas para poder obtener la matriz de correlación.

```{r}
# Transformar 'class' a variables binarias (0 y 1)
hepatitis$class <- ifelse(hepatitis$class == 'die', 0, 1)

# Transformar 'sex' a variables binarias (0 y 1)
hepatitis$sex <- ifelse(hepatitis$sex == 'female', 0, 1)

# Verificar los cambios en 'class' y 'sex'
print(str(hepatitis))
head(hepatitis[c('class', 'sex')])

```

La transformación de las variables categóricas a variables numéricas discretas ha resultado de la siguiente manera:

Variable 'class': live -\> 1 , die -\> 0.

Variable 'sex': male -\> 1, female -\> 0.

Esta transformación, además, consigue que todas las variables discretas estén normalizadas entre sí.

A continuación, se muestra la matriz de correlación y la gráfica que representa la correlación entre todas las variables.

```{r}
#install.packages("corrplot")
library(corrplot)

# Verificar la estructura y tipos de datos después de la conversión
str(hepatitis)

# Calcular la matriz de correlación solo con las variables numéricas
correlation_matrix <- cor(hepatitis)

# Visualizar la matriz de correlación
print(correlation_matrix)

# Ajustar la visualización del mapa de calor
corrplot(correlation_matrix, method = "color",addCoef.col = "black", tl.col = "black", tl.srt = 45, tl.cex = 0.7, number.cex = 0.4, mar = c(1,1,1,1))


```

En principio, podemos deducir que no están muy correlacionadas. Casi todas las variables se encuentran rondando valores menores que 0.5 excepto las variables 'fatigue'-'malaise' y 'malaise'-'anorexia'. Con respecto a la correlación con la variable dependiente (predictora), casi todas las variables presentan una correlación inversa, porque tienen un valor negativo. Hay variables que están muy cercanas a 0 que indica que no existe relación entre las mismas. Éstas son: sgot, liver_firm, liver_big. Estas variables podrían ser eliminadas porque no muestran resultados significativos con la variable dependiente, además, tampoco muestran evidencias signification de correlación entre el resto de las variables independientes.Por ello, se decide eliminar las variables 'sgot','liver_big', 'liver_firm'.

```{r}
# Seleccionar las variables que deseas mantener
hepatitis_reduced <- subset(hepatitis, select = -c(sgot, liver_firm, liver_big))

# Verificar la estructura del nuevo conjunto de datos
str(hepatitis_reduced)
head(hepatitis_reduced)
```

El conjunto de datos se reduce de 19 atributos a 16 atributos en su totalidad. Esta selección de atributos permitirá que los resultados del estudio sean más precisos y fiables.

## Selección de ejemplos

En este caso, como el conjunto de datos presenta un tamaño de 155 atributos. Como no es un tamaño demasiado grande como para eliminar ejemplos para obtener una mayor relevancia en el conjunto, se decide no realizar este paso en este estudio.

## Normalización

Hay algunos algoritmos que necesitan de la normalización de los datos, sobre todo en los algortimos relacionados con distancias como puede ser un K-Vecinos más cercanos en clasificación. 

```{r}
#para ello usaremos la función scale en todas las columnas que contengan valores continuos sobre los dos datasets tanto el reducido por la selección de atributos como el original

hepatitis_norm<-hepatitis%>%
mutate(age=scale(hepatitis$age),bilirubin=scale(hepatitis$bilirubin),alk_phosphate=scale(hepatitis$alk_phosphate),sgot=scale(hepatitis$sgot),albumin=scale(hepatitis$albumin))
head(hepatitis_norm[c('age', 'bilirubin','alk_phosphate','sgot','albumin')])
```


```{r}

hepatitis_reduced_norm<-hepatitis_reduced%>%
mutate(age=scale(hepatitis_reduced$age),bilirubin=scale(hepatitis_reduced$bilirubin),alk_phosphate=scale(hepatitis_reduced$alk_phosphate),albumin=scale(hepatitis_reduced$albumin))
head(hepatitis_reduced_norm[c('age', 'bilirubin','alk_phosphate','albumin')])
```

## Clustering

Sabemos que hay dos clases, vive o muere. A continuación usaremos el algoritmo K-Means para agrupar el conjunto de datos
```{r}
#quitamos la etiqueta de la clase
hepatitis_without_class <- subset(hepatitis_norm, select = -class)
head(hepatitis_without_class)


kMeansHepatitis <- kmeans(hepatitis_without_class,center=2,nstart=20)

summary(kMeansHepatitis)
```
```{r}
table(kMeansHepatitis$cluster)
```
```{r}
print(kMeansHepatitis)

```

```{r}
filas <- nrow(hepatitis)

aciertos <- 0
for(i in 1:filas){
  if(hepatitis[i,"class"]==0){
    valor <- kMeansHepatitis$cluster[i] == 1
    if(grepl("TRUE", valor)){
      aciertos = aciertos +1
    }
  }else{
    valor <- kMeansHepatitis$cluster[i] == 2
    if(grepl("TRUE", valor)){
      aciertos = aciertos +1
    }
  }
}

aciertos

```
Como podemos observar, si se agrupan en dos clusters, 98 irian al cluster 1 y 57 al cluster 2. En nuestro dataset hay 32 ejemplos correspondientes a "muere" y 123 correspondientes a "vive" y podríamos pensar que pueden estar medianamente bien diferenciados, en concreto, ha "acertado" 118 ejemplos de 155. Sin embargo, si observamos el valor de Between_SS / total_SS es de 19.99%, es un porcentaje muy bajo lo que indica que no hay una buena separación entre los clusters.

Vamos a ver cúal sería el número de clusters óptimos:

```{r}
wcss <- vector()
for(i in 1:50){
  wcss[i] <- sum(kmeans(hepatitis_without_class, i)$withinss)
}
ggplot() + geom_point(aes(x = 1:50, y = wcss), color = 'blue') + 
  geom_line(aes(x = 1:50, y = wcss), color = 'blue') + 
  ggtitle("Método del Codo") + 
  xlab('Cantidad de Centroides k') + 
  ylab('WCSS')
```

Como se puede observar, no hay un codo en el que se pueda determinar el número óptimo.


## Regresión

En este punto evaluaremos la capacidad de diferentes modelos de precedir valores a partir de datos previos, que serán tomados dividiendo el conjunto de entrenamiento mediante validación cruzada con k = 5,los modelos evaluados serán los siguientes: 
- Regresión lineal
- Random Forest
- KNN regresivo
Para cada uno de ellos calcularemos las siguientes métricas: 
- El error cuadrático medio.
- La raíz del error cuadrático medio.
- El error absoluto medio.
- R2.

Mediante estas métricas evaluaremos cuál de los modelos de regresión proporciona un mejor rendimiento para el dataset del problema.

En primer lugar realizaremos esta evaluación con el dataset completo ya preprocesado y con los datos numéricos normalizados:

```{r}

# Se realiza en primer lugar la regresión lineal
# La variable dependiente será el sexo y las independientes el resto
modelo <- lm(albumin ~ ., data = hepatitis_norm)

# Se muestran los coeficientes, p-valores y estadísticas de ajuste:
summary(modelo)

# El coeficiente de determinación (R2)
summary_modelo <- summary(modelo)
print(paste("R2:", summary_modelo$r.squared))

```

```{r}
# Cargando la librería randomForest
library(randomForest)

# Utilizaremos albumin como variable objetivo
data<-hepatitis_norm

# Entrenar el modelo Random Forest
# Supongamos que queremos predecir el consumo de combustible (mpg) usando las otras variables
set.seed(123)
rf_model <- randomForest(albumin ~ ., data = hepatitis_norm)

# Resumen del modelo
print(rf_model)

# Predicciones en los datos de entrenamiento
predictions <- predict(rf_model, hepatitis_norm)

actual_values <- hepatitis_norm$albumin

# Puedes evaluar la calidad de las predicciones calculando:

# El error cuadrático medio (MSE)
mse<- mean((actual_values - predictions)^2)
print(paste("MSE: ", mse))

# La raíz del error cuadrático medio (RMSE)
rmse <- sqrt(mean((actual_values - predictions)^2))
print(paste("RMSE:", rmse))

# El error absoluto medio (MAE)
mae <- mean(abs(actual_values - predictions))
print(paste("MAE:", mae))

# El coeficiente de determinación (R2)
SS_Res <- sum((actual_values - predictions)^2)
SS_Tot <- sum((actual_values - mean(actual_values))^2)
r_cuadrado <- 1 - (SS_Res / SS_Tot)
print(paste("R2:", r_cuadrado))
```
```{r}
#Se realizara el knn regresivo
# Cargando el paquete necesario
library(class)


# Definiendo las variables predictoras y la variable objetivo
predictors <- hepatitis_norm[, -4]
target <- hepatitis_norm[, 4]  


# Entrenar el modelo KNN Regression
set.seed(123)
k <- 5  # Número de vecinos
knn_model <- knn(train = predictors, test = predictors, cl = target, k = k)

# Puedes usar el modelo para hacer predicciones
predictions <- as.numeric(knn_model)


# Evaluaremos la calidad de las predicciones calculando:
# El error cuadrático medio (MSE)
mse<- mean((target - predictions)^2)
print(paste("MSE: ", mse))

# La raíz del error cuadrático medio (RMSE)
rmse <- sqrt(mean((target - predictions)^2))
print(paste("RMSE:", rmse))

# El error absoluto medio (MAE)
mae <- mean(abs(target - predictions))
print(paste("MAE:", mae))

# El coeficiente de determinación (R2)
SS_Res <- sum((target - predictions)^2)
SS_Tot <- sum((target - mean(target))^2)
r_cuadrado <- 1 - (SS_Res / SS_Tot)
print(paste("R2:", r_cuadrado))
```
Viendo estos resultados el modelo Random Forest tiene los mejores resultados, pero hay que tener en cuenta que estamos trabajando con un dataset bastante desequilibrado, por lo que se obtienen métricas de alto rendimiento sin realmente predecir el patron de los datos.

A continuación evaluaremos los mismos modelos, de nuevo dividiendo el conjunto de entrenamiento mediante validación cruzada con k = 5, pero esta vez con el dataset reducido, para comprobar si la selección de atributos era necesaria o no.

```{r}
# Se realiza en primer lugar la regresión lineal
# La variable dependiente será el sexo y las independientes el resto
modelo <- lm(albumin ~ ., data = hepatitis_reduced_norm)

# Se muestran los coeficientes, p-valores y estadísticas de ajuste:
summary(modelo)

# El coeficiente de determinación (R2)
summary_modelo <- summary(modelo)
print(paste("R2:", summary_modelo$r.squared))
```

```{r}
# Cargando la librería randomForest
library(randomForest)

# Utilizaremos albumin como variable objetivo
data<-hepatitis_reduced_norm

# Entrenar el modelo Random Forest
# Supongamos que queremos predecir el consumo de combustible (mpg) usando las otras variables
set.seed(123)
rf_model <- randomForest(albumin ~ ., data = hepatitis_reduced_norm)

# Resumen del modelo
print(rf_model)

# Predicciones en los datos de entrenamiento
predictions <- predict(rf_model, hepatitis_reduced_norm)

actual_values <- hepatitis_reduced_norm$albumin

# Puedes evaluar la calidad de las predicciones calculando:

# El error cuadrático medio (MSE)
mse<- mean((actual_values - predictions)^2)
print(paste("MSE: ", mse))

# La raíz del error cuadrático medio (RMSE)
rmse <- sqrt(mean((actual_values - predictions)^2))
print(paste("RMSE:", rmse))

# El error absoluto medio (MAE)
mae <- mean(abs(actual_values - predictions))
print(paste("MAE:", mae))

# El coeficiente de determinación (R2)
SS_Res <- sum((actual_values - predictions)^2)
SS_Tot <- sum((actual_values - mean(actual_values))^2)
r_cuadrado <- 1 - (SS_Res / SS_Tot)
print(paste("R2:", r_cuadrado))

```
```{r}
# Se realizara el knn regresivo
# Cargando el paquete necesario
library(class)


# Definiendo las variables predictoras y la variable objetivo
predictors <- hepatitis_reduced_norm[,-4]
target <- hepatitis_reduced_norm[,4]


# Entrenar el modelo KNN Regression
set.seed(123)
k <- 5  # Número de vecinos
knn_model <- knn(train = predictors, test = predictors, cl = target, k = k)

# Puedes usar el modelo para hacer predicciones
predictions <- as.numeric(knn_model)


# Evaluaremos la calidad de las predicciones calculando:
# El error cuadrático medio (MSE)
mse<- mean((target - predictions)^2)
print(paste("MSE: ", mse))

# La raíz del error cuadrático medio (RMSE)
rmse <- sqrt(mean((target - predictions)^2))
print(paste("RMSE:", rmse))

# El error absoluto medio (MAE)
mae <- mean(abs(target - predictions))
print(paste("MAE:", mae))

# El coeficiente de determinación (R2)
SS_Res <- sum((target - predictions)^2)
SS_Tot <- sum((target - mean(target))^2)
r_cuadrado <- 1 - (SS_Res / SS_Tot)
print(paste("R2:", r_cuadrado))
```
Vemos como los resultados obtenidos han sido peores que anteriormente, por lo que se puede concluir que no era necesaria la selección de atributos para este ejemplo concreto, aunque es una técnica que si que puede ser de gran utilidad en otros problemas.

## Clasificación

Los modelos de clasificación son algoritmos que se utilizan para predecir a qué categoría o clase pertenecerá una instancia basándose en sus características o atributos. Estos modelos se entrenan con datos históricos con ejemplos de instancias y sus respectivas etiquetas de clase.

En este punto evaluaremos diferentes modelos, dividiendo el conjunto mediante validación cruzada con k = 5,los modelos evaluados serán los siguientes: 

- Red neuronal: imita la estructura del cerebro. Consiste en nodos conectados con pesos ajustables. Toma entradas, realiza cálculos ponderados y produce salidas para clasificar datos. Durante el entrenamiento, ajusta los pesos para mejorar las predicciones

- Regresión logística: aunque su nombre incluye la palabra "regresión", la regresión logística se utiliza para problemas de clasificación binaria. Estima la probabilidad de que una instancia pertenezca a una clase particular y asigna la clase con la probabilidad más alta. Es un modelo lineal que utiliza la función logística para transformar la salida. 

- Maquinas de soporte vectorial(SVM): son modelos que buscan encontrar el hiperplano óptimo que mejor separa las instancias de diferentes clases en un espacio multidimensional. Pueden manejar problemas de clasificación lineal y no lineal.

- Random Forest: es un modelo de ensamble que combina múltiples árboles de decisión para mejorar la precisión y reducir el sobreajuste. Cada árbol se entrena con una muestra aleatoria de datos y realiza una predicción. La predicción final se obtiene mediante la votación de los árboles.  

- KNN: es un algoritmo simple que clasifica una instancia basándose en la mayoría de las clases de sus k vecinos más cercanos en el espacio de características. La elección del valor de k afecta la sensibilidad del modelo a los detalles locales y al ruido en los datos.

Para cada uno de ellos calcularemos las siguientes métricas: 

- Accuracy: Mide la proporción de predicciones correctas sobre el total de predicciones. Se calcula como (Verdaderos Positivos + Verdaderos Negativos) / Total. Indica la precisión general del modelo.

- Precisión: es una métrica que indica la proporción de instancias positivas clasificadas correctamente respecto a todas las positivas. Especifica la exactitud de las predicciones positivas.

- Error: mide la proporción de instancias mal clasificadas en relación con el total de instancias. Es la cantidad de predicciones incorrectas dividida por el número total de predicciones.

- AUC: mide la capacidad de un modelo de clasificación para distinguir entre clases asignando una puntuación más alta a las instancias positivas que a las negativas. Especifica la capacidad del modelo para clasificar correctamente las instancias en términos de sus probabilidades de pertenencia a una clase. 

- Especificidad: mide la proporción de instancias negativas que el modelo clasifica correctamente. Se calcula como Verdaderos Negativos / (Verdaderos Negativos + Falsos Positivos)

En datasets desbalanceados como en el que nos encontramos, el accuracy puede ser engañoso, ya que un modelo que predice siempre la clase mayoritaria podría tener un accuracy alto sin ser realmente útil, por eso hemos añadido la precisión que mide la exactitud de las predicciones positivas y la especifidad que indica qué proporción de las instancias que realmente son negativas fueron correctamente identificadas como negativas por el modelo.

Hay que tener en cuenta que el AUC se calcula si el algoritmo proporciona probabilidades, que es el caso de todos los nuestros.

Mediante estas métricas evaluaremos cuál de los modelos de clasificación proporciona un mejor rendimiento para el dataset del problema, en primer lugar realizaremos esta evaluación con el dataset completo ya preprocesado y con los datos numéricos normalizados.


```{r}
set.seed(123)
hepatitis_norm$class <- as.factor(hepatitis_norm$class)


# Definir el esquema de validación cruzada con k=5
control <- trainControl(method = "cv", number = 5, summaryFunction = multiClassSummary)


modelos_clasificacion <- list(
   "Red neuronal" = train(class ~ ., data=hepatitis_norm, method ="nnet",trControl=control,metric = "Specificity"),
  "Regresión Logística" = train(class ~ ., data = hepatitis_norm, method = "glm", trControl = control, family=binomial, metric = "Specificity"),
  "Máquinas de Vector de Soporte (SVM)" = train(class ~ ., data = hepatitis_norm, method = "svmRadial", trControl = control, metric = "Specificity"),
  "Random Forest" = train(class ~ ., data = hepatitis_norm, method = "rf", trControl = control, metric = "Specificity")
)


# Realizar experimentos con cada modelo y almacenar los resultados en un data frame
resultados_clasificacion <- data.frame(Accuracy = numeric(), 
                                       Precision = numeric(),
                                       Error = numeric(),
                                       Especificiad = numeric(),
                                       AUC = numeric(),
                                       Duracion = numeric(),
                                       stringsAsFactors = FALSE)

for (nombre_modelo in names(modelos_clasificacion)) {
  tiempo_inicial <- Sys.time()
  modelo <- modelos_clasificacion[[nombre_modelo]]

  predicciones <- predict(modelo, newdata = hepatitis_norm)
  #matriz de confusion 
  matrizConfusion <- confusionMatrix(predicciones, hepatitis_norm$class)
  print(matrizConfusion)
  #metricas
  accuracy <- matrizConfusion$overall["Accuracy"]
  error <- 1 - accuracy
  precision <- matrizConfusion$byClass["Sensitivity"]
  especificidad <- matrizConfusion$byClass["Specificity"]

   roc_obj <- roc(hepatitis_norm$class,
                              as.numeric(predict(modelo, newdata = hepatitis_norm, type = "raw")))
    auc <- auc(roc_obj)

  tiempo_final <- Sys.time()
  duracion <- tiempo_final - tiempo_inicial

  plot(roc_obj, col = "blue", lwd = 2, main = paste("Curva ROC", nombre_modelo))
  
  resultados_clasificacion[nombre_modelo, ] <- c(accuracy, precision, error, especificidad, auc, duracion)
}

# Mostrar los resultados
print(resultados_clasificacion)
```


A continuación, vamos a probar con el algoritmo KNN para ver su rendimiento en función el número de vecinos que se le asigne:


```{r}
#probamos knn con varios valores de k
valores <- expand.grid(k = seq(3, 15, 2)) 


# Aplica el método seleccionando el valor óptimo de k
knnClasification <- train(class ~ .,
      data = hepatitis_norm,
      method = 'knn',
      tuneGrid = valores,
      metric = "Specificity",
      trControl = control)
knnClasification
```
```{r}
plot(knnClasification, metric = "Specificity")
```


Viendo estos resultados el modelo Random Forest tiene los mejores resultados para el dataset de nuestro problema, esto se puede deber a varias razones, entre ellas nos gustaría destacar las siguientes: 

- Random Forest mitiga el problema del sobreajuste al promediar las predicciones de varios árboles, lo que proporciona un modelo más robusto y generalizable.

- En datasets pequeños, como es nuestro caso, la variabilidad en los resultados puede ser alta. Random Forest reduce la varianza al combinar múltiples árboles, lo que puede estabilizar las predicciones y hacer que el modelo sea más confiable.

- Random Forest puede manejar conjuntos de datos con un número relativamente bajo de ejemplos y características de manera efectiva. 

- Random Forest no es dependiente de grandes cantidades de datos, algunos modelos más avanzados, como las redes neuronales, pueden requerir grandes cantidades de datos para aprender patrones complejos de manera efectiva. Random Forest es más versátil en este sentido y puede proporcionar buenos resultados con conjuntos de datos más pequeños.

A continuación evaluaremos los mismos modelos, de nuevo dividiendo el conjunto de entrenamiento mediante validación cruzada con k = 5, pero esta vez con el dataset reducido, para comprobar si ha valido la pena la selección de atributos o si en este caso no era necesario.

```{r}

# Convertir la variable objetivo en factor para problemas de clasificación
hepatitis_reduced_norm$class <- as.factor(hepatitis_reduced_norm$class)

modelos_clasificacion_reduced <- list(
   "Red neuronal" = train(class ~ ., data=hepatitis_reduced_norm, method ="nnet",trControl=control,metric = "Specificity"),
  "Regresión Logística" = train(class ~ ., data = hepatitis_reduced_norm, method = "glm", trControl = control, family=binomial, metric = "Specificity"),
  "Máquinas de Vector de Soporte (SVM)" = train(class ~ ., data = hepatitis_reduced_norm, method = "svmRadial", trControl = control, metric = "Specificity"),
  "Random Forest" = train(class ~ ., data = hepatitis_reduced_norm, method = "rf", trControl = control, metric = "Specificity")
)


# Realizar experimentos con cada modelo y almacenar los resultados en un data frame
resultados_clasificacion_reduced <- data.frame(Accuracy = numeric(), 
                                       Precision = numeric(),
                                       Error = numeric(),
                                       Especificiad = numeric(),
                                       AUC = numeric(),
                                       Duracion = numeric(),
                                       stringsAsFactors = FALSE)

for (nombre_modelo_reduced in names(modelos_clasificacion_reduced)) {
  tiempo_inicial <- Sys.time()
  modelo <- modelos_clasificacion_reduced[[nombre_modelo_reduced]]

  predicciones <- predict(modelo, newdata = hepatitis_reduced_norm)
  #matriz de confusion 
  matrizConfusion <- confusionMatrix(predicciones, hepatitis_reduced_norm$class)
  print(matrizConfusion)
  #metricas
  accuracy <- matrizConfusion$overall["Accuracy"]
  error <- 1 - accuracy
  precision <- matrizConfusion$byClass["Sensitivity"]
  especificidad <- matrizConfusion$byClass["Specificity"]

   roc_obj <- roc(hepatitis_reduced_norm$class,
                              as.numeric(predict(modelo, newdata = hepatitis_reduced_norm, type = "raw")))
    auc <- auc(roc_obj)

  tiempo_final <- Sys.time()
  duracion <- tiempo_final - tiempo_inicial

  plot(roc_obj, col = "blue", lwd = 2, main = paste("Curva ROC", nombre_modelo))
  
  resultados_clasificacion_reduced[nombre_modelo_reduced, ] <- c(accuracy, precision, error, especificidad, auc, duracion)
}

# Mostrar los resultados
print(resultados_clasificacion_reduced)
```
Con el dataset reducido tras la selección de atributos, los resultados son muy parecidos, sin ninguna diferencia significativa con las pruebas llevadas a cabo que con el dataset completo, el modelo Random Forest sigue siendo el modelo que mejor resultados nos proporciona y que por tanto deberíamos elegir para llevar a cabo clasificación en nuestro problema.

Por lo tanto podemos decir que no merece la pena hacer la selección de atributos y utilizar un dataset reducido para este problema en concreto, aunque es una técnica que si que puede ser de gran utilidad en otros problemas.

